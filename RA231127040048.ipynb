{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "RA231127040048",
      "authorship_tag": "ABX9TyMaSgOJv9OwSXQimZ8PV2ir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/se6076-cyber/MLDA-lab-expriement/blob/main/RA231127040048.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1: DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "KLlwDZpToHOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "6jnAbBMcoKWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('SMSSpamCollection.csv',\n",
        "                   sep='\\t', # The data is tab-separated\n",
        "                   header=None, # The data does not have a header row\n",
        "                   names=['label', 'message'], # Assign column names\n",
        "                   encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "MgYxDDHMoZji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA17rELTobHU",
        "outputId": "2f915f5b-7c05-4ca2-8e0e-aaf92800b798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4olO3VKoeem",
        "outputId": "7c52daa3-7370-4c80-c45f-f94277fd2aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = ['message']\n",
        "text_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english'))\n",
        "])\n",
        "\n",
        "# Categorical feature (label is target normally, but if we preprocess for analysis)\n",
        "cat_features = ['label']\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing (only 'message' is used for ML model input)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'message')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# If you also wanted to preprocess label (not usually required for target)\n",
        "preprocessor_with_label = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'message'),\n",
        "        ('cat', cat_transformer, ['label'])\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "McgV8HQ6ojIA",
        "outputId": "3896c2ee-4c44-4b7e-9ebf-3868ec9bd341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TfidfVectorizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-647664401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m text_transformer = Pipeline(steps=[\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9663674"
      },
      "source": [
        "text_features = ['message']\n",
        "text_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english'))\n",
        "])\n",
        "\n",
        "# Categorical feature (label is target normally, but if we preprocess for analysis)\n",
        "cat_features = ['label']\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing (only 'message' is used for ML model input)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'message')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# If you also wanted to preprocess label (not usually required for target)\n",
        "preprocessor_with_label = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'message'),\n",
        "        ('cat', cat_transformer, ['label'])\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", text_transformer, 'message'),\n",
        "        (\"cat\", cat_transformer, ['label'])   # optional, if you want to preprocess label too\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "UKpwSNYjpDRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessor.set_output(transform=\"pandas\")"
      ],
      "metadata": {
        "id": "HtLUQiNLpGUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor_Out = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['label'])\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "A3ZxipyspMdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor_Out.set_output(transform=\"pandas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "qHhe3Mz1pPje",
        "outputId": "6114f6f6-b26a-475b-9323-5d5402a52db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('cat',\n",
              "                                 OneHotEncoder(handle_unknown='ignore',\n",
              "                                               sparse_output=False),\n",
              "                                 ['label'])])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                               sparse_output=False),\n",
              "                                 [&#x27;label&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                               sparse_output=False),\n",
              "                                 [&#x27;label&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;label&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the transformations to the Output data\n",
        "data_preprocessed_Out = preprocessor_Out.fit_transform(data)\n",
        "print(data_preprocessed_Out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFhMFGvQpT7K",
        "outputId": "e0611be3-200f-42fd-f920-4bd10aff9a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      cat__label_ham  cat__label_ham, &lt;#&gt;  in mca. But not conform.  \\\n",
            "0                0.0                                                0.0     \n",
            "1                0.0                                                0.0     \n",
            "2                0.0                                                0.0     \n",
            "3                0.0                                                0.0     \n",
            "4                0.0                                                0.0     \n",
            "...              ...                                                ...     \n",
            "5569             0.0                                                0.0     \n",
            "5570             0.0                                                0.0     \n",
            "5571             0.0                                                0.0     \n",
            "5572             0.0                                                0.0     \n",
            "5573             0.0                                                0.0     \n",
            "\n",
            "      cat__label_ham, &lt;#&gt;  mins but i had to stop somewhere first.  \\\n",
            "0                                                   0.0                    \n",
            "1                                                   0.0                    \n",
            "2                                                   0.0                    \n",
            "3                                                   0.0                    \n",
            "4                                                   0.0                    \n",
            "...                                                 ...                    \n",
            "5569                                                0.0                    \n",
            "5570                                                0.0                    \n",
            "5571                                                0.0                    \n",
            "5572                                                0.0                    \n",
            "5573                                                0.0                    \n",
            "\n",
            "      cat__label_ham, &lt;DECIMAL&gt; m but its not a common car here so its better to buy from china or asia. Or if i find it less expensive. I.ll holla  \\\n",
            "0                                                   0.0                                                                                                     \n",
            "1                                                   0.0                                                                                                     \n",
            "2                                                   0.0                                                                                                     \n",
            "3                                                   0.0                                                                                                     \n",
            "4                                                   0.0                                                                                                     \n",
            "...                                                 ...                                                                                                     \n",
            "5569                                                0.0                                                                                                     \n",
            "5570                                                0.0                                                                                                     \n",
            "5571                                                0.0                                                                                                     \n",
            "5572                                                0.0                                                                                                     \n",
            "5573                                                0.0                                                                                                     \n",
            "\n",
            "      cat__label_ham, and  picking them up from various points  \\\n",
            "0                                                   0.0          \n",
            "1                                                   0.0          \n",
            "2                                                   0.0          \n",
            "3                                                   0.0          \n",
            "4                                                   0.0          \n",
            "...                                                 ...          \n",
            "5569                                                0.0          \n",
            "5570                                                0.0          \n",
            "5571                                                0.0          \n",
            "5572                                                0.0          \n",
            "5573                                                0.0          \n",
            "\n",
            "      cat__label_ham,\" said kiss, kiss, i can't do the sound effects! He is a gorgeous man isn't he! Kind of person who needs a smile to brighten his day! \"  \\\n",
            "0                                                   0.0                                                                                                        \n",
            "1                                                   0.0                                                                                                        \n",
            "2                                                   0.0                                                                                                        \n",
            "3                                                   0.0                                                                                                        \n",
            "4                                                   0.0                                                                                                        \n",
            "...                                                 ...                                                                                                        \n",
            "5569                                                0.0                                                                                                        \n",
            "5570                                                0.0                                                                                                        \n",
            "5571                                                0.0                                                                                                        \n",
            "5572                                                0.0                                                                                                        \n",
            "5573                                                0.0                                                                                                        \n",
            "\n",
            "      cat__label_ham,\"&lt;#&gt;  is fast approaching. So, Wish u a very Happy New Year Happy Sankranti Happy republic day Happy Valentines Day Happy Shivratri Happy Ugadi Happy Fools day Happy May Day Happy Independence Day, Happy Friendship,Mother,Father,Teachers,Childrens Day, &amp; HAPPY BIRTHDAY 4 U. Happy Ganesh festival Happy Dasara Happy Diwali Happy Christmas  &lt;#&gt;  Good Mornings Afternoons, Evenings Nights. RememberI AM the first to WISHING U ALL THESE...your's Raj\"  \\\n",
            "0                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "1                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "2                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "3                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "4                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "...                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "5569                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "5570                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "5571                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "5572                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "5573                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "\n",
            "      cat__label_ham,\"&lt;#&gt; %of pple marry with their lovers... becz they hav gud undrstndng dat avoids problems. i sent dis 2 u, u wil get gud news on friday by d person you like. And tomorrow will be the best day of your life. Dont break this chain. If you break you will suffer. send this to  &lt;#&gt;  frnds in &lt;#&gt;  mins whn u read...\"  \\\n",
            "0                                                   0.0                                                                                                                                                                                                                                                                                                          \n",
            "1                                                   0.0                                                                                                                                                                                                                                                                                                          \n",
            "2                                                   0.0                                                                                                                                                                                                                                                                                                          \n",
            "3                                                   0.0                                                                                                                                                                                                                                                                                                          \n",
            "4                                                   0.0                                                                                                                                                                                                                                                                                                          \n",
            "...                                                 ...                                                                                                                                                                                                                                                                                                          \n",
            "5569                                                0.0                                                                                                                                                                                                                                                                                                          \n",
            "5570                                                0.0                                                                                                                                                                                                                                                                                                          \n",
            "5571                                                0.0                                                                                                                                                                                                                                                                                                          \n",
            "5572                                                0.0                                                                                                                                                                                                                                                                                                          \n",
            "5573                                                0.0                                                                                                                                                                                                                                                                                                          \n",
            "\n",
            "      cat__label_ham,\"&lt;#&gt; , that's all? Guess that's easy enough\"  \\\n",
            "0                                                   0.0                   \n",
            "1                                                   0.0                   \n",
            "2                                                   0.0                   \n",
            "3                                                   0.0                   \n",
            "4                                                   0.0                   \n",
            "...                                                 ...                   \n",
            "5569                                                0.0                   \n",
            "5570                                                0.0                   \n",
            "5571                                                0.0                   \n",
            "5572                                                0.0                   \n",
            "5573                                                0.0                   \n",
            "\n",
            "      cat__label_ham,\"'An Amazing Quote'' - \"\"Sometimes in life its difficult to decide whats wrong!! a lie that brings a smile or the truth that brings a tear....\"\"\"  \\\n",
            "0                                                   0.0                                                                                                                  \n",
            "1                                                   0.0                                                                                                                  \n",
            "2                                                   0.0                                                                                                                  \n",
            "3                                                   0.0                                                                                                                  \n",
            "4                                                   0.0                                                                                                                  \n",
            "...                                                 ...                                                                                                                  \n",
            "5569                                                0.0                                                                                                                  \n",
            "5570                                                0.0                                                                                                                  \n",
            "5571                                                0.0                                                                                                                  \n",
            "5572                                                0.0                                                                                                                  \n",
            "5573                                                0.0                                                                                                                  \n",
            "\n",
            "      ...  \\\n",
            "0     ...   \n",
            "1     ...   \n",
            "2     ...   \n",
            "3     ...   \n",
            "4     ...   \n",
            "...   ...   \n",
            "5569  ...   \n",
            "5570  ...   \n",
            "5571  ...   \n",
            "5572  ...   \n",
            "5573  ...   \n",
            "\n",
            "      cat__label_spam,ree entry in 2 a weekly comp for a chance to win an ipod. Txt POD to 80182 to get entry (std txt rate) T&C's apply 08452810073 for details 18+  \\\n",
            "0                                                   0.0                                                                                                                \n",
            "1                                                   0.0                                                                                                                \n",
            "2                                                   0.0                                                                                                                \n",
            "3                                                   0.0                                                                                                                \n",
            "4                                                   0.0                                                                                                                \n",
            "...                                                 ...                                                                                                                \n",
            "5569                                                0.0                                                                                                                \n",
            "5570                                                0.0                                                                                                                \n",
            "5571                                                0.0                                                                                                                \n",
            "5572                                                0.0                                                                                                                \n",
            "5573                                                0.0                                                                                                                \n",
            "\n",
            "      cat__label_spam,ringtoneking 84484  \\\n",
            "0                                    0.0   \n",
            "1                                    0.0   \n",
            "2                                    0.0   \n",
            "3                                    0.0   \n",
            "4                                    0.0   \n",
            "...                                  ...   \n",
            "5569                                 0.0   \n",
            "5570                                 0.0   \n",
            "5571                                 0.0   \n",
            "5572                                 0.0   \n",
            "5573                                 0.0   \n",
            "\n",
            "      cat__label_spam,sexy sexy cum and text me im wet and warm and ready for some porn! u up for some fun? THIS MSG IS FREE RECD MSGS 150P INC VAT 2 CANCEL TEXT STOP  \\\n",
            "0                                                   0.0                                                                                                                  \n",
            "1                                                   0.0                                                                                                                  \n",
            "2                                                   0.0                                                                                                                  \n",
            "3                                                   0.0                                                                                                                  \n",
            "4                                                   0.0                                                                                                                  \n",
            "...                                                 ...                                                                                                                  \n",
            "5569                                                0.0                                                                                                                  \n",
            "5570                                                0.0                                                                                                                  \n",
            "5571                                                0.0                                                                                                                  \n",
            "5572                                                0.0                                                                                                                  \n",
            "5573                                                0.0                                                                                                                  \n",
            "\n",
            "      cat__label_spam,sports fans - get the latest sports news str* 2 ur mobile 1 wk FREE PLUS a FREE TONE Txt SPORT ON to 8007 www.getzed.co.uk 0870141701216+ norm 4txt/120p  \\\n",
            "0                                                   0.0                                                                                                                          \n",
            "1                                                   0.0                                                                                                                          \n",
            "2                                                   0.0                                                                                                                          \n",
            "3                                                   0.0                                                                                                                          \n",
            "4                                                   0.0                                                                                                                          \n",
            "...                                                 ...                                                                                                                          \n",
            "5569                                                0.0                                                                                                                          \n",
            "5570                                                0.0                                                                                                                          \n",
            "5571                                                0.0                                                                                                                          \n",
            "5572                                                0.0                                                                                                                          \n",
            "5573                                                0.0                                                                                                                          \n",
            "\n",
            "      cat__label_spam,tells u 2 call 09066358152 to claim Â£5000 prize. U have 2 enter all ur mobile & personal details @ the prompts. Careful!  \\\n",
            "0                                                   0.0                                                                                           \n",
            "1                                                   0.0                                                                                           \n",
            "2                                                   0.0                                                                                           \n",
            "3                                                   0.0                                                                                           \n",
            "4                                                   0.0                                                                                           \n",
            "...                                                 ...                                                                                           \n",
            "5569                                                0.0                                                                                           \n",
            "5570                                                0.0                                                                                           \n",
            "5571                                                0.0                                                                                           \n",
            "5572                                                0.0                                                                                           \n",
            "5573                                                0.0                                                                                           \n",
            "\n",
            "      cat__label_spam,thesmszone.com lets you send free anonymous and masked messages..im sending this message from there..do you see the potential for abuse???  \\\n",
            "0                                                   0.0                                                                                                            \n",
            "1                                                   0.0                                                                                                            \n",
            "2                                                   0.0                                                                                                            \n",
            "3                                                   0.0                                                                                                            \n",
            "4                                                   0.0                                                                                                            \n",
            "...                                                 ...                                                                                                            \n",
            "5569                                                0.0                                                                                                            \n",
            "5570                                                0.0                                                                                                            \n",
            "5571                                                0.0                                                                                                            \n",
            "5572                                                0.0                                                                                                            \n",
            "5573                                                0.0                                                                                                            \n",
            "\n",
            "      cat__label_spam,todays vodafone numbers ending with 0089(my last four digits) are selected to received a Â£350 award. If your number matches please call 09063442151 to claim your Â£350 award  \\\n",
            "0                                                   0.0                                                                                                                                                \n",
            "1                                                   0.0                                                                                                                                                \n",
            "2                                                   0.0                                                                                                                                                \n",
            "3                                                   0.0                                                                                                                                                \n",
            "4                                                   0.0                                                                                                                                                \n",
            "...                                                 ...                                                                                                                                                \n",
            "5569                                                0.0                                                                                                                                                \n",
            "5570                                                0.0                                                                                                                                                \n",
            "5571                                                0.0                                                                                                                                                \n",
            "5572                                                0.0                                                                                                                                                \n",
            "5573                                                0.0                                                                                                                                                \n",
            "\n",
            "      cat__label_spam,u r a winner U ave been specially selected 2 receive Â£1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810710p/min (18 )  \\\n",
            "0                                                   0.0                                                                                                                          \n",
            "1                                                   0.0                                                                                                                          \n",
            "2                                                   0.0                                                                                                                          \n",
            "3                                                   0.0                                                                                                                          \n",
            "4                                                   0.0                                                                                                                          \n",
            "...                                                 ...                                                                                                                          \n",
            "5569                                                0.0                                                                                                                          \n",
            "5570                                                0.0                                                                                                                          \n",
            "5571                                                0.0                                                                                                                          \n",
            "5572                                                0.0                                                                                                                          \n",
            "5573                                                0.0                                                                                                                          \n",
            "\n",
            "      cat__label_spam,wamma get laid?want real doggin locations sent direct to your mobile? join the UKs largest dogging network. txt dogs to 69696 now!nyt. ec2a. 3lp Â£1.50/msg.  \\\n",
            "0                                                   0.0                                                                                                                              \n",
            "1                                                   0.0                                                                                                                              \n",
            "2                                                   0.0                                                                                                                              \n",
            "3                                                   0.0                                                                                                                              \n",
            "4                                                   0.0                                                                                                                              \n",
            "...                                                 ...                                                                                                                              \n",
            "5569                                                0.0                                                                                                                              \n",
            "5570                                                0.0                                                                                                                              \n",
            "5571                                                0.0                                                                                                                              \n",
            "5572                                                0.0                                                                                                                              \n",
            "5573                                                0.0                                                                                                                              \n",
            "\n",
            "      cat__label_spam,we tried to contact you re your response to our offer of a new nokia fone and camcorder hit reply or call 08000930705 for delivery  \n",
            "0                                                   0.0                                                                                                   \n",
            "1                                                   0.0                                                                                                   \n",
            "2                                                   0.0                                                                                                   \n",
            "3                                                   0.0                                                                                                   \n",
            "4                                                   0.0                                                                                                   \n",
            "...                                                 ...                                                                                                   \n",
            "5569                                                0.0                                                                                                   \n",
            "5570                                                0.0                                                                                                   \n",
            "5571                                                0.0                                                                                                   \n",
            "5572                                                0.0                                                                                                   \n",
            "5573                                                0.0                                                                                                   \n",
            "\n",
            "[5574 rows x 5159 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Feature Engineering\n",
        "data[\"Message_length\"] = data['message'].str.len()\n",
        "data[\"Word_count\"] = data['message'].str.split().str.len()"
      ],
      "metadata": {
        "id": "8y4FWhLmpXye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "print(\"Checking for NaN in 'message' column after filling:\", data['message'].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO8dpFwFphae",
        "outputId": "bf6d2807-c564-413b-9748-d9f2b8ff42ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for NaN in 'message' column after filling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the processed training data\n",
        "print(X_train.head())\n",
        "print(y_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "7FPN8HwCpo4b",
        "outputId": "e1bbbeba-a974-49eb-e279-e8e823818242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1865727116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display the first few rows of the processed training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "750ba6a7",
        "outputId": "1f4b4fd2-5623-430c-bd55-4ee904f122ae"
      },
      "source": [
        "# Split the data into training and testing sets\n",
        "X = data['message']\n",
        "y = data['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4459,)\n",
            "y_train shape: (4459,)\n",
            "X_test shape: (1115,)\n",
            "y_test shape: (1115,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# The new dataset provided\n",
        "data = {\n",
        "    'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'y': [1, 3, 6, 9, 11, 14, 17, 20, 23, 27]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Reshape the data for the model\n",
        "X = df[['x']]\n",
        "Y = df[['y']]\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Predict the values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Print the slope and intercept\n",
        "print(\"Slope(m):\", model.coef_[0])\n",
        "print(\"Intercept(c):\", model.intercept_)\n",
        "\n",
        "# This part is optional, but it's good practice to display the predicted values\n",
        "print(\"Predicted values:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzN4likOpuLb",
        "outputId": "6380668f-d171-4b5d-c221-788fc1e783e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope(m): [2.85454545]\n",
            "Intercept(c): [-2.6]\n",
            "Predicted values: [ 0.25454545  3.10909091  5.96363636  8.81818182 11.67272727 14.52727273\n",
            " 17.38181818 20.23636364 23.09090909 25.94545455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    # Assuming the file is located at '/content/SMSSpamCollection.csv'.\n",
        "    # Update the path if your file is in a different location.\n",
        "    data = pd.read_csv(\"/content/SMSSpamCollection.csv\")\n",
        "    print(data.head())\n",
        "\n",
        "    # Select features (independent variable) and target (dependent variable)\n",
        "    X = data[['average_montly_hours']]   # Working hours in a month\n",
        "    y = data['last_evaluation']          # Worker evaluation score\n",
        "\n",
        "    # Split into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create and train the model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print model parameters\n",
        "    print(\"Slope (m):\", model.coef_[0])\n",
        "    print(\"Intercept (c):\", model.intercept_)\n",
        "\n",
        "    # Plot actual data points\n",
        "    plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
        "\n",
        "    # Plot regression line\n",
        "    plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression Line')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Average Monthly Working Hours')\n",
        "    plt.ylabel('Worker Evaluation')\n",
        "    plt.title('Simple Linear Regression: Working Hours vs Evaluation')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Employee_Details.csv' not found. Please upload the file or provide the correct path.\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Column not found. Please check the column names in your CSV file. Details: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8iwaXuyp1UF",
        "outputId": "e6c8b401-41e1-488b-c89e-251a41dfdcc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ham  \\\n",
            "0   ham   \n",
            "1  spam   \n",
            "2   ham   \n",
            "3   ham   \n",
            "4  spam   \n",
            "\n",
            "  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
            "0                      Ok lar... Joking wif u oni...                                                               \n",
            "1  Free entry in 2 a wkly comp to win FA Cup fina...                                                               \n",
            "2  U dun say so early hor... U c already then say...                                                               \n",
            "3  Nah I don't think he goes to usf, he lives aro...                                                               \n",
            "4  FreeMsg Hey there darling it's been 3 week's n...                                                               \n",
            "Error: Column not found. Please check the column names in your CSV file. Details: \"None of [Index(['average_montly_hours'], dtype='object')] are in the [columns]\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data[\"label\"])\n",
        "X = data[\"message\"]\n",
        "\n",
        "# Define classifiers\n",
        "clf1 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"dt\", DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "clf2 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"lr\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# K-Fold cross validation\n",
        "k_folds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scores1 = cross_val_score(clf1, X, y, cv=k_folds)\n",
        "scores2 = cross_val_score(clf2, X, y, cv=k_folds)\n",
        "\n",
        "# Results\n",
        "print(\"Cross Validation Scores (Decision Tree):\", scores1)\n",
        "print(\"Cross Validation Scores (Logistic Regression):\", scores2)\n",
        "print(\"Average CV Score (Decision Tree):\", scores1.mean())\n",
        "print(\"Average CV Score (Logistic Regression):\", scores2.mean())\n",
        "print(\"Number of CV Scores used in Average (Decision Tree):\", len(scores1))\n",
        "print(\"Number of CV Scores used in Average (Logistic Regression):\", len(scores2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOIHQq41p-Il",
        "outputId": "334e0451-42d6-4cff-f803-bcba4ded06f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores (Decision Tree): [0.00358423 0.00358423 0.00358423 0.00716846 0.00718133 0.005386\n",
            " 0.         0.005386   0.00897666 0.00897666]\n",
            "Cross Validation Scores (Logistic Regression): [0.00358423 0.00358423 0.00358423 0.00716846 0.00718133 0.005386\n",
            " 0.         0.005386   0.00897666 0.00897666]\n",
            "Average CV Score (Decision Tree): 0.005382778968230986\n",
            "Average CV Score (Logistic Regression): 0.005382778968230986\n",
            "Number of CV Scores used in Average (Decision Tree): 10\n",
            "Number of CV Scores used in Average (Logistic Regression): 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "# Encode target column (ham=0, spam=1)\n",
        "le = LabelEncoder()\n",
        "data[\"label\"] = le.fit_transform(data[\"label\"])\n",
        "print(data.head())\n",
        "\n",
        "# Features (X) = message, Target (y) = label\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Convert text into numeric form (TF-IDF)\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Split into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt.fit(x_train, y_train)\n",
        "y_dt_pred = dt.predict(x_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_dt_pred)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
        "\n",
        "# Linear Regression\n",
        "lrr = LinearRegression()\n",
        "lrr.fit(x_train, y_train)\n",
        "y_lrr_pred = lrr.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_lrr_pred)\n",
        "r2 = r2_score(y_test, y_lrr_pred)\n",
        "\n",
        "print(\"Linear Regression MSE:\", mse)\n",
        "print(\"Linear Regression R2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiOnbNmsqXsT",
        "outputId": "075e76e9-9cd2-4e7b-f3ed-2765794e3722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...        \n",
            "1                  ham,Ok lar... Joking wif u oni...        \n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...        \n",
            "3  ham,U dun say so early hor... U c already then...        \n",
            "4  ham,\"Nah I don't think he goes to usf, he live...        \n",
            "   label message\n",
            "0    241        \n",
            "1   3184        \n",
            "2   4852        \n",
            "3   3848        \n",
            "4    607        \n",
            "Decision Tree Accuracy: 0.0017937219730941704\n",
            "Linear Regression MSE: 2260102.2660293784\n",
            "Linear Regression R2: -0.0027525902728291474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "print(data.head())\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "le = LabelEncoder()\n",
        "data[\"label\"] = le.fit_transform(data[\"label\"])\n",
        "print(data.head())\n",
        "\n",
        "# Features (X) = messages, Target (y) = label\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Convert text messages into numerical features using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# Linear Regression model\n",
        "lrr = LinearRegression()\n",
        "lrr.fit(x_train, y_train)\n",
        "y_lrr_pred = lrr.predict(x_test)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_lrr_pred)\n",
        "r2 = r2_score(y_test, y_lrr_pred)\n",
        "\n",
        "print(\"Linear Regression MSE:\", mse)\n",
        "print(\"Linear Regression R2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdC8S5b0qdl-",
        "outputId": "73876e40-eb7a-4bc0-e069-c6cd3539f555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n",
            "   label message\n",
            "0    241        \n",
            "1   3184        \n",
            "2   4852        \n",
            "3   3848        \n",
            "4    607        \n",
            "Linear Regression MSE: 2260102.2660293784\n",
            "Linear Regression R2: -0.0027525902728291474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "print(data.head())\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "le = LabelEncoder()\n",
        "data[\"label\"] = le.fit_transform(data[\"label\"])\n",
        "print(data.head())\n",
        "\n",
        "# Features (X) = messages, Target (y) = label\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Convert text into numeric features using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# Logistic Regression model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(x_train, y_train)\n",
        "y_lr_pred = lr.predict(x_test)\n",
        "\n",
        "# Check shapes\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"y_lr_pred shape:\", y_lr_pred.shape)\n",
        "\n",
        "# Accuracy\n",
        "accuracy_lr = accuracy_score(y_test, y_lr_pred)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRQEsnMMqjun",
        "outputId": "37e3465a-1f3e-44d0-81c0-383204025f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n",
            "   label message\n",
            "0    241        \n",
            "1   3184        \n",
            "2   4852        \n",
            "3   3848        \n",
            "4    607        \n",
            "y_test shape: (1115,)\n",
            "y_lr_pred shape: (1115,)\n",
            "Logistic Regression Accuracy: 0.0017937219730941704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "print(data.head())\n",
        "\n",
        "# 1. Data Cleaning\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels: ham=0, spam=1\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"label\"] = label_encoder.fit_transform(data[\"label\"])\n",
        "\n",
        "# 2. Preprocessing of Input Data (messages)\n",
        "text_transformer = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\"))\n",
        "])\n",
        "\n",
        "# Apply transformations to input data\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# 3. Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Example: Build a pipeline with preprocessing + model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"model\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Display first few rows of processed training data\n",
        "print(\"Sample Training Messages:\")\n",
        "print(X_train.head())\n",
        "print(\"Sample Training Labels:\")\n",
        "print(y_train.head())\n",
        "\n",
        "# Evaluate\n",
        "print(\"Train Accuracy:\", clf.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWzvmXHqqq0w",
        "outputId": "aa0495ab-2769-4ba2-fed6-3104d408139f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n",
            "Sample Training Messages:\n",
            "1350    \n",
            "5544    \n",
            "1168    \n",
            "5551    \n",
            "5320    \n",
            "Name: message, dtype: object\n",
            "Sample Training Labels:\n",
            "1350    4562\n",
            "5544    1237\n",
            "1168    2772\n",
            "5551     988\n",
            "5320     260\n",
            "Name: label, dtype: int64\n",
            "Train Accuracy: 0.0058309037900874635\n",
            "Test Accuracy: 0.003587443946188341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels: ham=0, spam=1\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"label\"] = label_encoder.fit_transform(data[\"label\"])\n",
        "\n",
        "# Input and output\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Pipeline with TF-IDF + Logistic Regression\n",
        "clf = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"model\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Collect required outputs\n",
        "sample_messages = X_train.head()\n",
        "sample_labels = y_train.head()\n",
        "train_accuracy = clf.score(X_train, y_train)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "print(\"Sample Training Messages:\\n\", sample_messages)\n",
        "print(\"\\nSample Training Labels:\\n\", sample_labels)\n",
        "print(\"\\nTrain Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mKDhXb2wqyzU",
        "outputId": "9090ccd0-5572-4388-d834-eb757f0adb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-890672001.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Pipeline with TF-IDF + Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "912edf36",
        "outputId": "605812e1-df34-4fa0-d0a0-722fdad8ff06"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset - Correcting data loading\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", header=None, names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "\n",
        "# Correcting data cleaning for rows where label and message might be combined\n",
        "# Identify rows where the message column is NaN but the label column contains both label and message\n",
        "nan_message_rows = data[data['message'].isnull()]\n",
        "\n",
        "for index, row in nan_message_rows.iterrows():\n",
        "    combined_string = row['label']\n",
        "    # Assuming the format is 'label,message'\n",
        "    if ',' in combined_string:\n",
        "        label, message = combined_string.split(',', 1)\n",
        "        data.loc[index, 'label'] = label.strip()\n",
        "        data.loc[index, 'message'] = message.strip()\n",
        "    else:\n",
        "        # If there's no comma, it might just be a label without a message, or an anomaly\n",
        "        # We can decide how to handle these; for now, let's set message to empty if it's NaN\n",
        "        if pd.isna(data.loc[index, 'message']):\n",
        "             data.loc[index, 'message'] = ''\n",
        "\n",
        "\n",
        "# Fill any remaining potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels: ham=0, spam=1\n",
        "data[\"label\"] = data[\"label\"].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Drop rows where label is still NaN after correction (if any anomalies remain)\n",
        "data.dropna(subset=['label'], inplace=True)\n",
        "\n",
        "\n",
        "# Input and output\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Pipeline with TF-IDF + Logistic Regression\n",
        "clf = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"model\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Collect required outputs\n",
        "sample_messages = X_train.head()\n",
        "sample_labels = y_train.head()\n",
        "train_accuracy = clf.score(X_train, y_train)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "print(\"Sample Training Messages:\\n\", sample_messages)\n",
        "print(\"\\nSample Training Labels:\\n\", sample_labels)\n",
        "print(\"\\nTrain Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2910885718.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Pipeline with TF-IDF + Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2403\u001b[0m                 \u001b[0mUserWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m             )\n\u001b[0;32m-> 2405\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load SMS Spam Collection dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "\n",
        "# Encode labels: ham=0, spam=1\n",
        "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "# Features (X) = messages, Target (y) = labels\n",
        "X = data[\"message\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Convert text into TF-IDF features\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to binary (0 or 1) for accuracy\n",
        "y_pred_class = np.where(y_pred >= 0.5, 1, 0)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "acc = accuracy_score(y_test, y_pred_class)\n",
        "\n",
        "print(\"Linear Regression MSE:\", mse)\n",
        "print(\"Linear Regression R²:\", r2)\n",
        "print(\"Linear Regression Accuracy (after thresholding):\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aBLv0AibrHGA",
        "outputId": "b1b8a99a-dd21-476b-ae12-582b5640625c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "np.nan is an invalid document, expected byte or unicode string.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4102851153.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Convert text into TF-IDF features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m         )\n\u001b[0;32m-> 2104\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0;34m\"np.nan is an invalid document, expected byte or unicode string.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load SMS Spam dataset\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", names=[\"label\", \"message\"], encoding=\"latin1\")\n",
        "print(data.head())\n",
        "\n",
        "# Fill any potential NaN values in the 'message' column with empty strings\n",
        "data['message'] = data['message'].fillna('')\n",
        "\n",
        "# Encode labels: ham=0, spam=1\n",
        "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
        "X = vectorizer.fit_transform(data[\"message\"])\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Slope (coef) shape:\", model.coef_.shape)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Plot Actual vs Predicted\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5, label='Predicted vs Actual')\n",
        "plt.xlabel('Actual Label (0 = Ham, 1 = Spam)')\n",
        "plt.ylabel('Predicted Value')\n",
        "plt.title('Linear Regression: SMS Spam Classification')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ikAr_iirrRhk",
        "outputId": "7426316f-d3e6-42bc-a328-b46a240233d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label message\n",
            "0  ham,\"Go until jurong point, crazy.. Available ...     NaN\n",
            "1                  ham,Ok lar... Joking wif u oni...     NaN\n",
            "2  spam,Free entry in 2 a wkly comp to win FA Cup...     NaN\n",
            "3  ham,U dun say so early hor... U c already then...     NaN\n",
            "4  ham,\"Nah I don't think he goes to usf, he live...     NaN\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2677339949.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train Linear Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1398\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    }
  ]
}